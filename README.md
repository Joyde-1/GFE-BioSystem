# GFE-BioSystem
The objective of this project is to develop and propose a framework for continuous multimodal recognition based on face, ear, and gait. The work employs Deep Learning models and utilizes both public datasets and data acquired via laboratory acquisition devices at STMLab to evaluate system performance in both controlled and "in the wild" scenarios. For the unimodal systems, models based on Deep Learning techniques were trained: YOLO and YOLO-Pose for detection, LDA and a Pyramidal Transformer for feature extraction. The results of the individual recognition systems and the two multimodal configurations were evaluated using metrics such as FAR, FRR, EER, accuracy, Rank metrics, and other performance indicators. Among all, the multimodal system based on the early fusion configuration showed the best performance, achieving an accuracy of 99.98%, a FAR of 0.0612%, FRR of 0%, and a minimum EER of 0.03%. Furthermore, it reached Rank-1 and Rank-5 values of 100%, demonstrating highly robust and effective recognition capabilities.
